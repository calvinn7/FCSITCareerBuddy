{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0                                    What is intern?   \n",
      "1                           Why do I need to intern?   \n",
      "2  Who do I need to seek approval for my internship?   \n",
      "3                                Where can I intern?   \n",
      "4                    What is the duration of intern?   \n",
      "\n",
      "                                              answer  \n",
      "0  An intern is a participant in an industrial tr...  \n",
      "1  Internships provide invaluable industrial expe...  \n",
      "2  Approval for internships is obtained from depa...  \n",
      "3  Interns can work at the physical location of a...  \n",
      "4  Internships typically last between 24 to 26 we...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "qa_df = pd.read_csv('D:/um/nlp/FCSITCareerBuddy/dataset/faq_data.csv')\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(qa_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SCSM11\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SCSM11\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SCSM11\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorize the questions in the dataset\n",
    "tfidf_matrix = vectorizer.fit_transform(qa_df['question'])\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Download necessary resources for NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Removing punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    \n",
    "    # Get the default stopwords list\n",
    "    default_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    # Words to remove from the stopwords list\n",
    "    words_to_keep = {'how', 'when', 'what','who','why','before','during','after'}\n",
    "\n",
    "# Customize stopwords by removing specific words\n",
    "    final_stopwords = default_stopwords - words_to_keep\n",
    "\n",
    "        # Removing stopwords\n",
    "    tokens = [token for token in tokens if token not in final_stopwords]\n",
    "    \n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens]  # Apply lower() to each token\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_question(input_question, threshold=0.001):\n",
    "    # Vectorize the input question\n",
    "    input_vector = vectorizer.transform([input_question])\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "    \n",
    "    # Get the index of the most similar question\n",
    "    most_similar_index = similarities.argmax()\n",
    "    most_similar_score = similarities[0, most_similar_index]\n",
    "    \n",
    "    if most_similar_score < threshold:\n",
    "        return {\n",
    "            \"answer\": \"Sorry, the answer to that question is not available in the data. Please ask your internship coordinator for the answer.\",\n",
    "            \"question\": \"\"\n",
    "        }\n",
    "    \n",
    "    return qa_df.iloc[most_similar_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Question: intern what\n",
      "Input Question: intern is what\n",
      "Most Similar Question: What is intern?\n",
      "Answer: An intern is a participant in an industrial training course, typically involving 12 credit hours of coursework and practical experience within a company.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"intern is what\"\n",
    "preprocessed_question = preprocess_text(question)\n",
    "print(\"Preprocessed Question:\", preprocessed_question)\n",
    "\n",
    "most_similar_question = get_most_similar_question(preprocessed_question )\n",
    "print(f\"Input Question: {question }\")\n",
    "print(f\"Most Similar Question: {most_similar_question['question']}\")\n",
    "print(f\"Answer: {most_similar_question['answer']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
